---
layout: post
title: "Understanding the Riemann Hypothesis"
date: 2024-08-19
usemathjax: true
---

<body markdown='1' style="text-align: justify;">

Recently I was fortunate enough to attend a talk by James Maynard on prime numbers and the Riemann Hypothesis. I now have a better understanding of the Riemann Hypothesis and its links to prime numbers than ever before, and I wanted to do a writeup both to consolidate my own understanding and of course to share the mathematical joy!

### Prime numbers

Suppose I wanted to understand $\mathbb{N} = \\{1, 2, 3, \dots\\}$. If I were a fan of addition (which I am), I might notice that almost by definition this set is generated by addition, and in fact we can generate it starting only with 1. But I am not only a fan of addition, I am also a fan of multiplication, and there are many questions we might want to ask about natural numbers that are more related to multiplication than addition. We might ask: is it possible to generate the natural numbers, preferably uniquely, with multiplication?

The answer is yes - if we ignore 1, the natural numbers are generated uniquely by multiplication of elements of the set $\\{2, 3, 5, 7, 11, \dots\\}$ - the prime numbers. And this fundamentally is why we care about prime numbers. Even though multiplication is really just spicy addition, multiplication on $\mathbb{N}$ gives us this remarkably rich and mysterious structure revolving around these numbers, which we don't have with vanilla addition. Hence the tradition of mathematicians caring about prime numbers - whenever you're doing multiplication (which is all the time), primes are often the basis of your understanding of all natural numbers.

But we might also have some questions about this seemingly God-given set in and of itself. For example, we might wonder how the prime numbers are distributed among the rest of the naturals; in doing so, we would be following Gauss in 1792, who conjectured that the density of primes around $n \in \mathbb{N}$ is approximately $\log n$ - that is, roughly 1 in every $\log n$ numbers around $n$ is prime, or the 'probability' of $n$ being prime is $\frac{1}{\log n}$. A natural next question concerns the prime counting function

$$
\pi(x) = |\{n \mid n \text{ prime, } n \leq x\}|
$$

which gives the number of primes less than or equal to a given value. If the 'probability' of $n$ being prime is $\frac{1}{\log n}$, then the 'expected' number of primes up to $x$ is

$$
\int_2^x \frac{1}{\log t}\; dt
$$

which cannot be expressed in terms of elementary functions - we refer to it as $\mathrm{Li}(x)$. Then the conjecture is that

$$
\lim_{x\rightarrow\infty}\frac{\pi(x)}{\mathrm{Li}(x)} = 1
$$

which intuitively means that $\pi(x)$ and $\mathrm{Li}(x)$ grow at the same rate - an alternative notation is $\pi(x) \sim \mathrm{Li}(x)$.

Let's do what Gauss did, and take a look at some numerical examples,

$$
\def\arraystretch{1.3}
\begin{array}{| c | c | c | c | c |}
\hline
x & \pi(x) & \mathrm{Li}(x) & |\pi(x)-\mathrm{Li}(x)| & \% \text{ error} \\
\hline
10^6 & 78498 & 78626.50\dots & 128.50\dots & 0.164\% \\
\hline
10^9 & 50847534 & 50849233.91\dots & 1699.91\dots & 0.00334\% \\
\hline
\end{array}
$$

and we might be led to conclude that Gauss was onto something. Indeed, he was. This result is the remarkable [Prime Number Theorem](https://en.wikipedia.org/wiki/Prime_number_theorem) (PNT), proven 100 years later in 1896 by Hadamard and de la Vall√©e Poussin.

But let's try and go a bit further. We know the percentage error goes to 0 thanks to the PNT, but what about the absolute error? How quickly or slowly does this grow; how good really is our approximation? Heuristically we observe that it's pretty good - the absolute error seems to have around half as many digits as the actual values of $\pi(x)$ and $\mathrm{Li}(x)$. What's a good function that halves the number of digits in a number? $\sqrt{x}$ will do the trick. And hence we state an even stronger conjecture:

$$
\begin{equation}
|\pi(x) - \mathrm{Li}(x)| < Cx^{1/2}\log x
\end{equation}
$$

for any sufficiently large $C$. Note the $\log x$ doesn't *really* matter, as this is on the order of the number of digits of $x$, far smaller than $\sqrt{x}$ which has half as many digits as $x$. But we include it to line up with our numerical evidence.

This, in fact, is the Riemann Hypothesis.

### The Riemann zeta function

It is probable that the vast majority of people familiar with the Riemann hypothesis understand it not as the above statement, but rather as a statement about the zeroes of a certain function $\zeta: \mathbb{C} \rightarrow \mathbb{C}$, the Riemann zeta function. The really, really remarkable thing is that these two statements are indeed equivalent. Let's explore why.

The Riemann zeta function is defined as follows:

$$
\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s} = \frac{1}{1^s} + \frac{1}{2^s} + \frac{1}{3^s} + \cdots
$$

where this converges, and its [analytic continuation](https://en.wikipedia.org/wiki/Analytic_continuation) - the most natural extension of the function to other values - elsewhere. But the really important equivalent definition that leads to the importance of this function in the study of prime numbers is

$$
\zeta(s) = \prod_{p \text{ prime}}\frac{1}{1-\frac{1}{p^s}} = \frac{1}{1-\frac{1}{2^s}} \cdot \frac{1}{1-\frac{1}{3^s}} \cdot \frac{1}{1-\frac{1}{5^s}} \cdots
$$

and the really wonderful thing about this statement is that it is a way of algebraically encapsulating the fundamental property of prime numbers, which is that they multiplicatively generate all natural numbers without repetition - it is due to this fact that the two definitions are equivalent.

We will now derive an entry result which is perhaps the most foundational theorem in all of analytic number theory. Metaphorically, we are about to climb the hill that will lead us to the view of the vast valley of analytic number theory lying before us.

We will consider, for reasons that will become apparent, $\log(\zeta(s))$ - intuitively this seems nice given the product nature of our second definition. We have that

$$
\begin{align*}
\log(\zeta(s)) &= \sum_{p \text{ prime}} \log \left(\frac{1}{1-p^{-s}}\right) \\
&= -\sum_{p \text{ prime}} \log \left(1-p^{-s}\right)
\end{align*}
$$

and we're going to differentiate with respect to $s$ on both sides:

$$
\begin{align*}
\frac{\zeta'(s)}{\zeta(s)} &= -\sum_{p \text{ prime}} \frac{p^{-s}\log p}{1-p^{-s}} \\
&= -\sum_{p \text{ prime}} p^{-s}\log p\left(1 + p^{-s} + p^{-2s} + \cdots\right) \\
&= -\sum_{p \text{ prime}} \log p\left(p^{-s} + p^{-2s} + p^{-3s} + \cdots\right) \\
&= -\sum_{p \text{ prime}} \sum_{\substack{n = p^k \\ n > 0}} \frac{\log p}{n^s} \\
\end{align*}
$$

and now it's helpful to introduce a little bit of notation. We define the von Mangoldt function $\Lambda(n)$:

$$
\Lambda(n) = \begin{cases}
\log p & n = p^k \text{ for a prime } p\\
0 & \text{otherwise}
\end{cases}
$$

and now we can say

$$
\sum_{n=1}^\infty \frac{\Lambda(n)}{n^s} = -\frac{\zeta'(s)}{\zeta(s)}
$$

which is a fairly remarkable result. The LHS is referred to as a Dirichlet series, and we can extract partial sums of the von Mangoldt function using [Perron's formula](https://en.wikipedia.org/wiki/Perron%27s_formula):

$$
\sum_{n \leq x}\Lambda(n) = -\frac{1}{2\pi i}\int_{2-i\infty}^{2+i\infty} \frac{\zeta'(s)}{\zeta(s)}x^s\; ds
$$

with the slight caveat that, if $x$ is an integer, we need to halve the last term in the summation. Now we have a nice contour integral on the RHS, and it's time to apply complex analysis magic in the form of the [residue theorem](https://en.wikipedia.org/wiki/Residue_theorem) to express the integral as a sum of the poles of the function (where it goes to infinity) - we can see that we'll have a pole wherever the denominator, $\zeta(s)$, is zero, and some bonus. We eventually get the stunning exact equality

$$
\sum_{n \leq x}\Lambda(n) = x - \sum_{\rho}\frac{x^\rho}{\rho} - \log 2\pi
$$

where the sum is over the zeroes of the zeta function (the same summation caveat holds). This is really a truly remarkable formula. An almost exact expression for the prime numbers is to be found only by examining the complex numbers for which the Riemann zeta function goes to 0. 

### Understanding the Riemann hypothesis

We might now understand why zeroes of the Riemann zeta function are related to prime numbers. Indeed, it turns out that the real part of the zeta zeroes are intricately related to $(1)$. To see this, recall that, when carrying out complex exponentiation, we split the exponent into its real and imaginary parts, so

$$
\begin{align*}
x^\rho &= x^{\mathrm{Re}(\rho)}\cdot x^{i\cdot\mathrm{Im}(\rho)} \\
&= x^{\mathrm{Re}(\rho)}\cdot e^{i\log x\cdot\mathrm{Im}(\rho)} \\
&= x^{\mathrm{Re}(\rho)}\left(\cos(\mathrm{Im}(\rho)\log x) + i \sin(\mathrm{Im}(\rho)\log x)\right)
\end{align*}
$$

and the fact that the LHS is clearly real guarantees that the imaginary part will cancel, so all we really care about is the real part: $x^{\mathrm{Re}(\rho)} \cdot \cos(\mathrm{Im}(\rho)\log x)$ - clearly the input to $\cos$ is real, so it varies between $-1$ and $1$, and so we conclude

$$
|\mathrm{Re}(x^\rho)| \leq x^{\mathrm{Re}(\rho)}
$$

Continuation of this reasoning leads to the result that, if $\beta$ is the maximal real part of all $\rho$ with $\zeta(\rho) = 0$, then we can formulate an analog of $(1)$ stating that [^1]

$$
|\pi(x) - \mathrm{Li}(x)| < Cx^\beta\log x
$$

Now everything comes together. The PNT is equivalent to the statement that all zeroes of the zeta function have real part $< 1$, so the percentage error compared to the main term goes to 0. The Riemann Hypothesis is equivalent to the statement that all zeroes have real part $\leq \frac{1}{2}$, so the absolute error grows as the square root of $x$. Finally, we recall the [functional equation for the zeta function](https://en.wikipedia.org/wiki/Riemann_zeta_function#Riemann's_functional_equation)

$$
\zeta(s) = 2^s\pi^{s-1}\sin\left(\frac{\pi s}{2}\right)\Gamma(1-s)\zeta(1-s)
$$

Now if $\zeta(\rho) = 0$, one of the terms on the RHS must also be 0. It can be checked that none of the terms can be 0 when $\rho$ is in the *critical strip* where $0 < \mathrm{Re}(\rho) < 1$ except for $\zeta(1-\rho)$, and so it must be that $\zeta(1-\rho) = 0$. Hence all zeroes in the critical strip are symmetrical across the critical line $\mathrm{Re}(s) = \frac{1}{2}$, so the presence of any zeroes with real part between $0$ and $\frac{1}{2}$ would imply the existence of zeroes with real part greater than $\frac{1}{2}$. Finally, it is easy to check that the only zeroes outside this range are the so-called trivial zeroes, with $\rho$ a negative even integer. Hence we reach the typical statement of the Riemann Hypothesis - that all non-trivial zeroes have real part exactly $\frac{1}{2}$.

To conclude below, we have a [gif from Wikipedia](https://commons.wikimedia.org/wiki/File:Riemann_Explicit_Formula.gif) of the explicit formula for the von Mangoldt summatory function in action. As we add more terms corresponding to zeroes of the zeta function, we find that the prime counting function is perfectly matched.

![Our Riemann zeta sum approximates the prime counting function better and better as we add more correction terms associated with the zeta zeroes.](/blog/assets/2024-08-19-understanding-the-riemann-hypothesis/explicit-formula.gif)

[^1]: We should also note that we have jumped here from the summatory von Mangoldt function, which counts powers of primes as well as primes themselves, to the vanilla prime counting function. This is justified by the fact that powers of primes are very rare, with on the order of $\log x$ of them below $x$ - this is totally insignificant compared to the absolute error of $x^\beta \log x$ that we are dealing with.